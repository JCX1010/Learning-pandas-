{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('survey_results_public.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Respondent',\n",
       " 'MainBranch',\n",
       " 'Hobbyist',\n",
       " 'OpenSourcer',\n",
       " 'OpenSource',\n",
       " 'Employment',\n",
       " 'Country',\n",
       " 'Student',\n",
       " 'EdLevel',\n",
       " 'UndergradMajor',\n",
       " 'EduOther',\n",
       " 'OrgSize',\n",
       " 'DevType',\n",
       " 'YearsCode',\n",
       " 'Age1stCode',\n",
       " 'YearsCodePro',\n",
       " 'CareerSat',\n",
       " 'JobSat',\n",
       " 'MgrIdiot',\n",
       " 'MgrMoney',\n",
       " 'MgrWant',\n",
       " 'JobSeek',\n",
       " 'LastHireDate',\n",
       " 'LastInt',\n",
       " 'FizzBuzz',\n",
       " 'JobFactors',\n",
       " 'ResumeUpdate',\n",
       " 'CurrencySymbol',\n",
       " 'CurrencyDesc',\n",
       " 'CompTotal',\n",
       " 'CompFreq',\n",
       " 'ConvertedComp',\n",
       " 'WorkWeekHrs',\n",
       " 'WorkPlan',\n",
       " 'WorkChallenge',\n",
       " 'WorkRemote',\n",
       " 'WorkLoc',\n",
       " 'ImpSyn',\n",
       " 'CodeRev',\n",
       " 'CodeRevHrs',\n",
       " 'UnitTests',\n",
       " 'PurchaseHow',\n",
       " 'PurchaseWhat',\n",
       " 'LanguageWorkedWith',\n",
       " 'LanguageDesireNextYear',\n",
       " 'DatabaseWorkedWith',\n",
       " 'DatabaseDesireNextYear',\n",
       " 'PlatformWorkedWith',\n",
       " 'PlatformDesireNextYear',\n",
       " 'WebFrameWorkedWith',\n",
       " 'WebFrameDesireNextYear',\n",
       " 'MiscTechWorkedWith',\n",
       " 'MiscTechDesireNextYear',\n",
       " 'DevEnviron',\n",
       " 'OpSys',\n",
       " 'Containers',\n",
       " 'BlockchainOrg',\n",
       " 'BlockchainIs',\n",
       " 'BetterLife',\n",
       " 'ITperson',\n",
       " 'OffOn',\n",
       " 'SocialMedia',\n",
       " 'Extraversion',\n",
       " 'ScreenName',\n",
       " 'SOVisit1st',\n",
       " 'SOVisitFreq',\n",
       " 'SOVisitTo',\n",
       " 'SOFindAnswer',\n",
       " 'SOTimeSaved',\n",
       " 'SOHowMuchTime',\n",
       " 'SOAccount',\n",
       " 'SOPartFreq',\n",
       " 'SOJobs',\n",
       " 'EntTeams',\n",
       " 'SOComm',\n",
       " 'WelcomeChange',\n",
       " 'SONewContent',\n",
       " 'Age',\n",
       " 'Gender',\n",
       " 'Trans',\n",
       " 'Sexuality',\n",
       " 'Ethnicity',\n",
       " 'Dependents',\n",
       " 'SurveyLength',\n",
       " 'SurveyEase']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape  # check out the dimension of the dataset\n",
    "df.dtypes  # look at the data types for each column\n",
    "df.head()  # read the first five rows\n",
    "df.tail()  # read the last five rows\n",
    "df.columns.values  # return an array of column names\n",
    "df.columns.values.tolist()  # return a list of column namesbikedata.shape  # check out the dimension of the dataset\n",
    "df.dtypes  # look at the data types for each column\n",
    "df.head()  # read the first five rows\n",
    "df.tail()  # read the last five rows\n",
    "df.columns.values  # return an array of column names\n",
    "df.columns.values.tolist()  # return a list of column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Missing Values\n",
    "\n",
    "Next, we would like to check if there are any missing values. To check this, we can use the function dataframe.isnull() in pandas. It will return True for missing components and False for non-missing cells. However, when the dimension of a dataset is large, it could be difficult to figure out the existence of missing values. In general, we may just want to know if there are any missing values first. The function dataframe.isnull().values.any() returns True when there is at least one missing value occurring in the data. The function dataframe.isnull().sum().sum() returns the number of missing values in the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()  # checking missing values\n",
    "df.notnull()  # checking non-missing values\n",
    "df.isnull().values.any()  # only want to know if there are any missing values\n",
    "df.notnull().sum()  # knowling number of non-missing values for each variable\n",
    "df.isnull().sum().sum()  # knowing how many missing values in the data\n",
    "df[\"MainBranch\"].isnull().values.any()  # only want to know if there are any missing values in MainBranch\n",
    "df[\"Country\"].isnull().values.any()\n",
    "df[\"Country\"].isnull().sum()  # return the number of missing values in Country "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get information without missing values\n",
    "\n",
    "A simple way to deal with data containing missing values is to skip rows with missing values in the dataset. \n",
    "\n",
    "df[df[\"Country\"].notnull()]  # the data contain rows that no missing values in Country\n",
    "\n",
    "no_missing = df.dropna()  # drop missing values and assign the data to no_missing\n",
    "\n",
    "clean_missing_rows = df.dropna(how=\"all\")  # drop rows where all cells in the row in NA and assign the data to clean_missing_rows\n",
    "\n",
    "df.dropna(axis=1, how=\"all\")  # drop columns if they only contain missing values\n",
    "\n",
    "df.dropna(thresh=25)  # drop rows that contain less than 25 non-missing values\n",
    "\n",
    "Note: If we use dataframe.dropna(thresh=25) to drop rows that contain less than 25 non-missing values, we don't change the original data. We can assign the output to a new variable or save the changes to the original data right away by using dataframe.dropna(thresh=25, inplace=True). In our example, it should be bikedata.dropna(thresh=25, inplace=True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Subsets \n",
    "\n",
    "subset4 = df.iloc[:100, :]   a subset of the first 100 rows of the original data\n",
    "\n",
    "subset5 = df.iloc[:, :3]   a subset of the first 3 columns of the original data\n",
    "\n",
    "subset6 = df.iloc[:100, :15]   a subset of the first 100 rows and the first 15 columns\n",
    "\n",
    "subset7 = df[[\"CNN\", \"FROM_ST\", \"TO_ST\", \"SHAPE_LENG\"]]   a subset contains variables CNN, FROM_ST, TO_ST, and SHAPE_LENG\n",
    "\n",
    "subset8 = df.sample(n=1000)   a random sample of size 1000 without replacement (replace = False (Default))\n",
    "\n",
    "subset9 = df.sample(frac=0.1, replace=True)   a random sample of 10% of the original data with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent</th>\n",
       "      <th>MainBranch</th>\n",
       "      <th>Hobbyist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am a student who is learning to code</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I am a student who is learning to code</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I am not primarily a developer, but I write co...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88878</th>\n",
       "      <td>88377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88879</th>\n",
       "      <td>88601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88880</th>\n",
       "      <td>88802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88881</th>\n",
       "      <td>88816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88882</th>\n",
       "      <td>88863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88883 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Respondent                                         MainBranch Hobbyist\n",
       "0               1             I am a student who is learning to code      Yes\n",
       "1               2             I am a student who is learning to code       No\n",
       "2               3  I am not primarily a developer, but I write co...      Yes\n",
       "3               4                     I am a developer by profession       No\n",
       "4               5                     I am a developer by profession      Yes\n",
       "...           ...                                                ...      ...\n",
       "88878       88377                                                NaN      Yes\n",
       "88879       88601                                                NaN       No\n",
       "88880       88802                                                NaN       No\n",
       "88881       88816                                                NaN       No\n",
       "88882       88863                                                NaN      Yes\n",
       "\n",
       "[88883 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset5 = df.iloc[:, :3]\n",
    "subset5\n",
    "df.loc[:,'Respondent':'Hobbyist'] \n",
    "# both lines of code produces the same output "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
